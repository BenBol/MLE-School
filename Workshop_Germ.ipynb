{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wenn Sie dieses Notizbuch in GOOGLE COLAB ausführen, müssen Sie die folgenden Befehle einmal auskommentieren und ausführen!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# import sys\n",
    "# drive.mount('/content/gdrive')\n",
    "# !git clone https://github.com/BenBol/MLE-School.git\n",
    "# sys.path.append('MLE-School')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SummerSchool22](https://github.com/BenBol/MLE-School/blob/main/03_images/SummerSchool22.png?raw=true)\n",
    "Falls Sie keine Internetverbindung haben, können Sie das Bild (und Folgende) lokal öffnen indem Sie den Link durch \n",
    "`03_Images/SummerSchool22.png` ersetzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation handgeschriebener Zahlen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moin und herzlich willkommen zu diesem interaktiven Kurs, in dem wir mit neuronalen Netzen handgeschriebene Buchstaben und Ziffern identifizieren wollen.\n",
    "\n",
    "**Einführung:**\n",
    "- Sie sollten die gekennzeichneten Programmstellen modifizieren und können den Funktionsabschnitt direkt ausführen. Ergänzen Sie  dazu den Code zwischen ### Anfang ### und ### Ende ###.\n",
    "- Um einen Funktionsabschnitt ausführen zu können, müssen Sie ihn auswählen und anschließend `STRG` + `ENTER` drücken.\n",
    "- Es wird Python 3 verwendet. \n",
    "\n",
    "**Motivation für neuronale Netze:**\n",
    "\n",
    "Es gilt: Je mehr Daten zur Verfügung stehen, desto größer ist der Vorteil von neuronalen Netzen gegenüber traditionellen Machine Learning Konzepten. \n",
    "\n",
    "- Rasanter Anstieg der Anzahl\n",
    "    - vernetzer Geräte und\n",
    "    - erzeugter Daten (im mehrfachen Zeta-Bite Bereich pro Jahr) \n",
    "    - Größe der Daten (Bsp. Beschleuniger / riesige Datenmengen die vorgefiltert werden müssen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einführung "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt viele Möglichkeiten neuronale Netze mit open Source Bibliotheken zu trainieren. In Python ist Sciki-Learn eine Einstiegsvariante.<br> \n",
    "Mehr Möglichkeit in der Gestaltung von neuronalen Netzen bietet [TensorFlow](https://www.tensorflow.org), welches wir im Folgenden verwenden werden. \n",
    "<br><br>\n",
    "[TensorFlow](https://www.tensorflow.org) ist eine einfach zu verwendende, aber leistungsstarke Deep-Learning-Bibliothek für Python. In diesem Kurs werden wir, ein neuronales Feedforward-Netzwerk erstellen und darauf trainieren, handgeschriebene Zeichen zu erkenenn <br>\n",
    "\n",
    "Der Datensatz den wir für diese Aufgabe verwenden werden ist ebenfalls öffentlich zugänglich und heißt [MNIST](http://yann.lecun.com/exdb/mnist/).<br><br>\n",
    "![MNIST Beispiel](https://github.com/BenBol/MLE-School/blob/main/03_images/Beispiel1.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevanter Pakete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zu beginn jedes Projektes werden die wichtigsten Pakete importiert, die im weiterem Verlauf benötigt werden. Hierzu gehört [Matplotlib](https://matplotlib.org) um Grafiken zu generieren und [Numpy](https://numpy.org) für das ausführen von Vektorrechnungen und natürlich das [Keras](https://keras.io) Paket aus [TensorFlow](https://www.tensorflow.org) für die Erstellung der Neuronalen Netze.\n",
    "\n",
    "**Aufgabe:** Führen Sie die Zelle aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import für Vektorrechnung\n",
    "import numpy as np\n",
    "\n",
    "# import für Grafiken\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Tensorflow für die Erstellung der Neuronalen Netze\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusätzlich stellen wir kleine Hilfsfunktionen, die sich in der Python Datei: `Hilfsfunktionen.py` befinden.\n",
    "\n",
    "**Aufgabe:** importieren sie alle Funktionen, indem Sie die Zelle ausführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Hilfsfunktionen import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der [MNIST](http://yann.lecun.com/exdb/mnist/) Datensatz ist wurde aus dem deutlich größeren [NIST](https://www.nist.gov/srd/nist-special-database-19) Datensatz aus dem Jahre 1995 generiert. Hierzu wurden ursprünglichen Schwarz-Weiß-Bilder der Zahlen 0-9 in der Größe zu 20x20 Pixeln normalisiert. (Daher die auftretenden leichten Graustufen).\n",
    "Die Bilder wurden anschließend in einem 28x28-Bild zentriert, indem der Massenschwerpunkt der Pixel berechnet und das Bild so verschoben wurde, dass dieser Punkt in der Mitte des 28x28-Feldes liegt.\n",
    "\n",
    "Der Datensatz ist in dem Ordner `./01_Dataset/mnist.npz` gespeichert und kann mit der Funktion ```mnist_daten, mnist_label = lade_daten(path)``` geladen werden.\n",
    "\n",
    "**Aufgabe**: Lade den Datensatz wie oben beschrieben.<br>\n",
    "**Reminder**: Fügen Sie den Code zwischen `### Anfang ###` und `### Ende ###` ein und ändern Sie `./01_Dataset/mnist.npz` in `'MLE-School/01_Dataset/mnist.npz'`, wenn Sie **COLAB** verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anfang ####\n",
    "path = ...\n",
    "mnist_daten, mnist_label = ...\n",
    "### Ende ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim Laden des Datensatzes werden zwei NumPy-Arrays zurückgegeben.</br>\n",
    "* Die Variable `mnist_daten` enthält dabei die einzelnen Bilder \n",
    "* Die Varialbe `mnist_label` besteht aus den numerischen Ziffern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erkunden Sie die Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lassen Sie uns gemeinsam den Datensatz zunächst einmal genauer betrachten.\n",
    "* Mit `type(Variable)` kann der Typ der Variable angezeigt werden \n",
    "* und `len(Variable)` gibt die Anzahl an Einträgen aus\n",
    "\n",
    "**Aufgabe**: Testen Sie beide Befehle um den Typ und die Länge beider Variablen zu bestimmen und prüfen Sie ob die Anzahl der Labels der Anzahl an Datenpunkten entspricht. (Reminder: mit dem `print(...)` Befehl können mehrere Ausgaben einer Zelle ausgegeben werden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anfang ####\n",
    "...\n",
    "...\n",
    "### Ende ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Bibliothek Numpy hat das dem Attribut `Variable.shape` implementiert, was eine genauere Information über die Dimensionen der Vektoren gibt.\n",
    "**Aufgabe:** Verwenden Sie das `shape` Attribut für beide Variablen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anfang ####\n",
    "dim_data = ...\n",
    "dim_label = ...\n",
    "print('Dimensionen datensatz: {}\\nDimensionen label:     {}'.format(dim_data, dim_label))\n",
    "### Ende ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz besteht demnach wie erwartet aus 70000 Ziffern, mit je 28x28 Pixelxn und der dazugehörigen Zahl in dem Label-Vektor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Darstellen der einzelnen Zahlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um nun die einzelnen Beispiele zu betrachten, können diese mit der Funktion `plt.imshow(Datensatz)` dargestellt werden. Um eine einzelne Zahl aus dem Datensatz zu erhalten, kann diese durch das \"Slicing\" mit `Datensatz[index]` ausgewählt werden.<br>\n",
    "**Aufgabe**: Plotten sie verschiedene Zahlen von dem Datensatz `mnist_daten`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Anfang ####\n",
    "...\n",
    "### Ende ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir stellen Ihnen hier eine Funktion zur Verfügung, mit der sie mehrere zufällige Bilder darstellen können.<br>\n",
    "**Aufgabe**: verwenden Sie die Funktion `plotte_Zahlen(n_Zeilen, n_Spalten, daten, label)` um ein Grid von 4x5 Zahlen zu plotten.\n",
    "***Anmerkung***:  Da die Zahlen zufällig gezeigt werden, kann man diese Funktion auch öfter ausführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anfang ###\n",
    "...\n",
    "### Ende ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden werden die Farbwerte der Zahlen näher betrachtet. Hierzu wird eine zufällige Zahl und zusätzlich ein Histogramm angezeigt, in dem die Verteilung der Farbwerte dargestellt ist. \n",
    "\n",
    "Auch diese Zeile kann öffters ausgeführt werden, um verschiedene Zahlen zu betrachten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = plotte_Zahlen(1,1,mnist_daten, mnist_label)\n",
    "plt.hist(mnist_daten[index].reshape(784), bins=20)\n",
    "plt.title(\"Verteilung der Pixelwerte\")  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie erwartet weisen die meisten Pixel eine Intensität von Null mit der Ausnahme der dunklen Zahl auf.\n",
    "Schwarz ist hierbei wie bei üblich als 255 definiert. Einiege wenige Pixel besitzen einen Grauwert, der aus dem Anti-Alising Verfahren zur Skalierung resultiert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anzahl der einzelnen Zahlen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weiterhin ist interesant, wie viele Bilder jeder Zahl in den Datensatz überhaupt vorhanden sind. Dazu wird im folgenden die häufigkeit der jeweiligen Klassen dargestellt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zahl, häufigkeit_im_Datensatz = np.unique(mnist_label, return_counts=True)\n",
    "plt.bar(Zahl, häufigkeit_im_Datensatz)\n",
    "plt.xlabel('Nummer in dem Bild')\n",
    "plt.ylabel('Anzahl in dem Datensatz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man sieht, sind nicht alle Zahlen in der selben Häufigkeit vorhanden. Bei starken Abweichungen könnte man dies weiter berücksichtigen. Für diese Übung ist dies nicht nötig."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufbereitung der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das Training der Neuronalen Netze mit *Dense-Layern* ist es vorteilhaft, wenn die Bilder nicht als 28x28-Vektor sondern als 784x1 Vektor vorliegen.\n",
    "\n",
    "Mit der Funktion `Vektor_neu = Vektor.reshape((b,c))` kann eine Matrix mit den Dimensionen `Vektor.shape == 'a,b'` in `Vektor_neu.shape == 'b,c'` umgeformt werden.\n",
    "Hierbei müssen die Dimensionen natürlich passen.\n",
    "\n",
    "<img src=\"https://github.com/BenBol/MLE-School/blob/main/03_images/Reshape.svg?raw=true\" width=350 />\n",
    "<br>\n",
    "**Aufgabe:** Formen Sie den Datensatz mit den Dimensionen `70000 x 28 x 28` zu den Dimensionen `70000 x 784`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anfang ####\n",
    "mnist_reshape = ...\n",
    "### Ende ###\n",
    "\n",
    "print('Neue Dimensionen: {}'.format(mnist_reshape.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typischerweise werden die Gewichte zwischen den Neuronen eines Neuronalen Netzes in einem Bereich zwischen Null und eins initiiert.  \n",
    "Wenn nun Werte zwischen 0-255 (von unserem Datensatz bisher) dem ANN als Input gegeben werden, muss dieses in den ersten Schritten des Trainings sich an den Bereich anpassen. Das ist zwar möglich, aber verlängert die Trainingszeit unnötig und macht das neuronale Netz unter Umständen unzuverlässiger.\n",
    "\n",
    "**Aufgabe** Normieren Sie die Farbwerte von dem Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normierung der Farbwerte\n",
    "### Anfang ###\n",
    "mnist_normiert = mnist_reshape / ...\n",
    "### Ende ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ausgabe unseres neuronalen Netzes soll zwischen den zehn verschiedenen Klassen unterscheiden.\n",
    "Dies könnte man über einen Neuron mit einer linearen Aktivierungsfunktion trainieren.\n",
    "Es hat sich jedoch gezeigt dass Klassifikation viel besser mit 10 Ausgabe Neuronen mit logistischen Aktivierungsfunktionen funktionieren.<br><br>\n",
    "Hierbei, wird das Netz trainiert, die höchste Ausgabe an dem Neuron der zugehörigen Klasse zu generieren.\n",
    "Also müssen die Label mit dem sogenannten One-Hot-Encoding angepasst werden und aus einem Vektor mit Integern wird eine Matrix mit Nullen und Einsen.\n",
    "Dies ist Beispielhaft in dem Folgenden Bild dargestellt.<br>\n",
    "\n",
    "<img src=\"https://github.com/BenBol/MLE-School/blob/main/03_images/To_Categorical.svg?raw=true\" width=500 />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformieren in eine One-Hot-Matrix\n",
    "label_one_hot = keras.utils.to_categorical(mnist_label, dtype =\"bool\") # Datentyp: Boolean. Was ist das? Warum?\n",
    "\n",
    "#Anzeige der Operation\n",
    "[print(mnist_label[i], label_one_hot[i]) for i in range(10)]\n",
    "print('\\nDimensionen des neuen Vektors:',label_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unterteilung in Test- und Trainingsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abschließend ist es noch t den Datensatz in einen Test- und einen Evaluationsdatensatz zu unterteilen. Unser Algorithmus wird auf den Trainingsdatensatz trainiert. Anschließend wird mit dem angepassten neuronalen Netz der Evaluationsdatensatz vorhergesagt um den Algorithmus zu evaluieren.<br><br>\n",
    "\n",
    "Hierzu wird die bereits existiertende Funktion `train_test_split` von `Scikit-Learn` zunächst importiert und ausgeführt.<br>\n",
    "Als Argument der Funktion werden zunächst der Datensatz, und die Label angegeben. Anschließend wird definiert wie viel Prozent der Daten pseudo-zufällig in den Testdatensatz gewählt werden. Außerdem ist es möglich durch die Angabe eines `random_state` zu definieren, dass bei jedem Ausführen dieser Funktion die selben Zahlen ausgewählt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_evaluation, y_train, y_evaluation = train_test_split(mnist_normiert, \n",
    "                                                    label_one_hot, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)\n",
    "\n",
    "print('Dimensionen der Trainingsdaten:',X_train.shape)\n",
    "print('Dimensionen der Testdaten:     ',X_evaluation.shape)\n",
    "print('Dimensionen der Trainingslabel:',y_train.shape)\n",
    "print('Dimensionen der Testlabel:     ',y_evaluation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition des Neuronalen Netzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netzwerk Architektur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Daten sind nun vorbereitet und das Training des neuronalen Neztes kann beginnen. Im ersten Versuch werden wir ein neuronales Netz mit 64 Neuronen in der ersten und 32 Neuronen in der zweiten Schicht, ähnlich zu dem abgebildeten Netz. Als letzte Schicht wird eine Schicht mit 10 Neuronen verwendet, so dass jedes Neuron die Klassenzugehörigkeit zu einer der 10 Klassen angibt. Um diese Zugehörigkeit zu werten, verwenden wir eine `softmax`- Aktivierungsfunktion \n",
    "\n",
    "<img src=\"https://github.com/BenBol/MLE-School/blob/main/03_images/ANN_MNIST.svg?raw=true\" width=500 />\n",
    "\n",
    "Die *Keras* Bibliothek von Tensorflow wurde ja bereits in der ersten Zelle importiert und kann nun verwendet werden.<br><br> \n",
    "Mit `keras.Sequential(...)` wird ein sequentieller Aufbau des Netzwerks definiert und zwischen den Klammern können beliebig viele Schichten und Netzwerkarchitekturen definiert werden. Um ein Feed-Forward Netzwerk zu erstellen, das wir bereits mathematisch in den Folien beschrieben haben, verwenden wir eine Abfolge von **Dense**-Schichten. **Dense**-Schichten definieren, dass jedes Neuron der vorherigen Schicht mit jedem Neuron dieser Schicht über Gewichte verbunden ist. Diese Schichten werden mit `keras.layer.Dense(n_neuronen, activation='Aktivierung')` definiert.<br>\n",
    "\n",
    "**Aufgabe** Definieren Sie ein sequenzielles Netzwerk mit drei Schichten, mit `[64, 32, 10]` Neuronen und den Aktivierungsfunktionen `['relu', 'relu', 'softmax']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition des Modells\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        ### Anfang ###\n",
    "        keras.layers.Dense(..., activation='...',input_shape=(784,)),\n",
    "        keras.layers.Dense(..., activation='...'),\n",
    "        keras.layers.Dense(..., activation='...')\n",
    "        ### Ende ###\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kompilierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir mit dem Training beginnen können, müssen wir den Trainingsprozess konfigurieren. Hierzu werden die **drei Schlüsselfaktoren** für den Kompilierungsschritt definiert:<br>\n",
    "\n",
    "**Der Optimierer.** Wir bleiben bei einem ziemlich guten Standard: dem gradientenbasierten Optimierer namens [`adam`](https://arxiv.org/abs/1412.6980). \n",
    "In Keras sind [viele weitere Optimieriungsalgorithmen](https://keras.io/losses/) bereits implementiert, die Sie sich ebenfalls ansehen können.<br>\n",
    "\n",
    "**Die Metrik**. In Keras sind ebenfalls [viele Metriken](https://keras.io/api/metrics/) zur Evaluation des Algorithmus implementiert. Da es sich um ein Klassifizierungsproblem handelt, nutzen wir den Ausgabewert von Keras, um die Genauigkeit (`accuracy`) zu bestimmen.<br>\n",
    "\n",
    "**Die Verlustfunktion**. Da wir eine Softmax-Ausgabeschicht verwenden, werden wir die Cross-Entropie-Loss verwenden. Keras unterscheidet zwischen `binary_crossentropy` (2 Klassen) und `categorical_crossentropy` (>2 Klassen). Wir wählen also letzere.\n",
    "Weitere Verlust-Funktionen sind unter [Keras-Verlustfunktionen](https://keras.io/losses/) aufgelistet. <br><br>\n",
    "\n",
    "**Aufgabe:** Definieren sie den Kompilierungsschritt des neuronalen Netzes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompilierungs des sequentiellen Modells\n",
    "### Anfang ###\n",
    "model.compile(loss='...', metrics=['...'], optimizer='...')\n",
    "### Ende ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Trainieren eines Modells in Keras besteht nur aus dem Ausführen von `model.fit()`. Hierbei gibt es noch einige mögliche Parameter, aber wir werden nur vier manuell angeben:\n",
    "\n",
    "**Die Trainingsdaten** (Bilder und Label), allgemein bekannt als `X_train`,`y_train`.<br>\n",
    "**Die Anzahl der Epochen** (Iterationen über den gesamten Datensatz), für die trainiert werden soll. wir starten mit `20` Epochen.<br>\n",
    "**Die Stapelgröße** (Anzahl der Bilder pro Gradienten-Update), die beim Training verwendet werden soll. Mögliche Werte sind `1024` oder `2048`, aber auch fast jeder andere Wert der kleiner als die Anzahl der Bilder ist.<br>\n",
    "**Der Testdaten-Split**: Wir haben unsere Daten bereits in Trainings- und Evalutionsdaten unterteilt. Mit dem Testdaten-Split definieren wir nun, dass der Algoritmus zur Evaluation des Trainings, zufälig 20% aus den Trainingsdaten wählt. So halten wir den Evaluationsdatensatz zur objektiven Beurteilung des Alroithmus vor.\n",
    "<br><br>\n",
    "\n",
    "**Aufgabe:** Ergänzen Sie die Angaben und starten Sie das Training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training des Modells\n",
    "### Anfang ###\n",
    "history = model.fit(X..., \n",
    "                    y..., \n",
    "                    epochs=...,\n",
    "                    batch_size=..., \n",
    "                    validation_split=0.2)\n",
    "### Ende ###\n",
    "\n",
    "\n",
    "# Speichern des Netzwerks\n",
    "path_to_model = 'keras_mnist.h5'\n",
    "model.save(path_to_model)\n",
    "print('Das Modell wurde als: \"%s\" gespeichert\\n' % path_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn das Training startet, wird die Zeit pro Schritt, und die momentanen Werte für den *loss* und die *accuracy* jeweils für das Test- und Trainingsset angezeigt. So ist es einfach den Verlauf des Trainings bereits beim Training zu verfolgen und eventuelle Fehler frühzeitig zu bemerken. \n",
    "\n",
    "Der Algorithmus ist jetzt trainiert und das Modell wurde für eine weitere Verwendung mit dem Befehl:`model.save('Pfad')` gespeichert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation des Trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Nun lassen wir uns  Trainingsverlauf anzeigen. Dazu haben wir im vorherigen Schritt den Trainingsfortschritt in die Variable `history` schreiben lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lade des Netzwerks\n",
    "path_to_model = 'keras_mnist.h5'\n",
    "model = keras.models.load_model(path_to_model)\n",
    "print('Das Modell: \"%s\" wurde geladen\\n' % path_to_model)\n",
    "\n",
    "# Anzeige des Trainingsfortschritt - Präzision\n",
    "plt.plot(history.history['accuracy'])# je nach Keras Version auch 'acc'\n",
    "plt.plot(history.history['val_accuracy']) # je nach Keras Version auch 'val_acc'\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Accuracy Trainingssatz', 'Accuracy Testsatz'], loc='lower right')\n",
    "\n",
    "# Anzeige des Trainingsfortschritt - Loss\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Verlust Trainingssatz', 'Verlust Testsatz'], loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach einem starken Anstieg in den ersten beiden Epochen, konvergiert die Genauigkeit des Trainings-Set gegen 100% und der Verlust (Loss) konvergiert gegen Null. Ein weiteres Training wird also voraussichtlich beide Werte weiterhin optimieren. Die Werte des Test-Datensatz hingegen scheinen schon nahezu das Optimum erreicht zu haben. Dies könnte an der geringen Größe des Netzwerks liegen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation auf die Test-Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir mit dem Netzwerk den Teil der Daten, der für die Evaluation abgespalten wurde vorher zu sagen. Dies wird mit dem Attribut `Vorhersage = model.predict(X)` der Modell Klasse ermöglicht. Als Ergebnis bekommen wir die Ausgabe der Softmax Schicht. Ein Beispiel wird mit dem Code der Zelle unter der Aufgabe angezeigt. <br>\n",
    "**Aufgabe:** Überprüfen Sie das trainierte Netzwerk mit dem `X_evaluation` Datensatz und ändern Sie den Index um verschiedene Ergebisse zu testen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anfang ###\n",
    "vorhersage = ...\n",
    "### Ende ###\n",
    "\n",
    "index=1\n",
    "plt.imshow(X_evaluation[index].reshape(28,28))\n",
    "print(np.vstack((range(10),np.round(vorhersage[index],1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es müssen nicht alle Werte manuell überprüft werden. Mit der Funktion: `model.evaluate(X,y)`können alle Vorhersagen auf einmal analysiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(X_evaluation, y_evaluation)\n",
    "\n",
    "print(\"Test Loss:     %.3f\"% loss_and_metrics[0])\n",
    "print(\"Test Accuracy: %.2f\"% (loss_and_metrics[1]*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis ist schon relativ gut. Spannender als **alle** Vorhersagen zu betrachten, ist es nur die falsch vorhergesagten anzeigen zu lassen.<br>\n",
    "**Aufgabe:** Führen Sie folgenden Code mehrmals aus um die falschen Vorhersagen zu plotten. Beachten Sie, dass vorher noch entschieden werden muss, in welche Zeile `==` (gleich) und `!=` (ungleich) geschrieben werden muss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umkehrung von one-Hot\n",
    "vorhersage_numerisch = np.argmax(vorhersage, axis=1)\n",
    "y_eval_numerisch = np.argmax(y_evaluation, axis=1)\n",
    "\n",
    "# Vergleich der Vektoren\n",
    "### Anfang ###\n",
    "incorrect_indices = np.where(vorhersage_numerisch ... y_eval_numerisch)[0]\n",
    "correct_indices = np.where(vorhersage_numerisch ... y_eval_numerisch)[0]\n",
    "### Ende ###\n",
    "\n",
    "print(len(correct_indices),\" richitg klassifiziert\")\n",
    "print(len(incorrect_indices),\" falsch klassifiziert\")\n",
    "\n",
    "def plot_incorrect_samples():\n",
    "    # adapt figure size to accomodate 18 subplots\n",
    "\n",
    "    figure_evaluation = plt.figure(figsize=(10,7.5))\n",
    "\n",
    "    # plot 9 incorrect predictions\n",
    "    for i, incorrect in enumerate(np.random.choice(incorrect_indices,12)):\n",
    "        plt.subplot(3,4,i+1)\n",
    "        plt.imshow(X_evaluation[incorrect].reshape(28,28),  )\n",
    "        plt.title(\"Predicted {}, Truth: {}\".format(vorhersage_numerisch[incorrect], y_eval_numerisch[incorrect]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "plot_incorrect_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei einigen dieser falschen Vorhersagen, ist es nachvollziehbar, dass diese nicht erkannt wurden. Aber die meisten Bilder wurden ja richtig erkannt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusions Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn bietet die Möglichkeit, eine Confusions Matrix zu Generieren. In dieser werden die Vorhersagen mit den wahren Werten verglichen. Auf der Diagonalen steht dabei die Genauigkeit, mit der die jeweilige Zahl vorher gesagt wird. Neben der Diagonalen steht die Prozentzahl, der falsch vorhergesagten Werte.\n",
    "\n",
    "**Aufgabe:** Plotten Sie die Confusionsmatrix mit der Funktion: `plot = plot_confusion_matrix(y_true, y_pred, normalize=True)`. Setzen Sie dabei die richtigen Variablen für `y_true` und `y_pred` ein. Was können Sie aus dieser Grafik ableiten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anfang ###\n",
    "...\n",
    "### Ende ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation der Netze mit einem Bild mit Zahlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie haben jetzt ein Modell, das mit einer relativ hohen Genauigkeit die Zahlen zwischen 0-9 Vorhersagen kann.<br>\n",
    "Mit ein bisschen Bilderkennung, kann man Muster auf einem einfarbigen Hintergrund erkennen und dies als Input für ein Neuronales Netz aufbereiten. <br>\n",
    "Hierzu haben wir ein Script für die Erkennung der Muster und anschließenden Klassifikation geschrieben und zur Verfügung gestellt. Dieses Script kann über die Funktion `klassifiziere_bild(path_to_image, path_to_model)` ausgeführt werden.<br> Hierbei ist `path_to_image` der Pfad zu einem Bild mit Text und `path_to_model` der Pfad zu dem Modell, das wir soeben trainiert haben.\n",
    "\n",
    "**Aufgabe** Evaluieren Sie Ihr Netzwerk mit den Bildern `'02_Test-images/n1.jpg'`,`'02_Test-images/n2.jpg'`und `'02_Test-images/n3.jpg'`<br>\n",
    "**Erinnerung** Fügen Sie den MLE-Ordner wie folgt hinzu: `'MLE-School/02_Test-images/n1.jpg'` wenn Sie **COLAB** verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Anfang ###\n",
    "...\n",
    "...\n",
    "...\n",
    "### Ende ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimierung der Netzwerkarchitektur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Herzlichen Glückwunsch**, <br>\n",
    "der Grundstein ist gelegt und Sie haben ein künstliches neuronales Netzwerk trainiert das in der Lage ist, geschriebene Ziffern zu erkennen. Somit haben Sie den Grunstein für ein Programm zur Texterkennung gelegt, wie beispielsweise Apple es vor einem Monat für die IPhones vorgestellt hat.<br><br>\n",
    "**Aber** das System ist noch nicht perfekt und Sie können jetzt anfangen die Parametern zu optimieren, um die Vorhersage weiter zu verbessern.\n",
    "\n",
    "**Aufgabe:** Variieren Sie die oben bereits eingeführten Parameter und evaluieren Sie den Einfluss auf die Präzision des Ergebnises. Die folgenden Überschriften werden Sie durch den Prozess leiten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition von Netzwerk V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Netzwerkarchitektur sollten Sie zwei wichtige Änderungen einbringen. Einerseits kannn die Anzahl an Schichten und Neuronen erhöht werden und eine Regularisierungstechnik sollte implementiert werden. \n",
    "\n",
    "**Anpassen der Architektur**<br>\n",
    "Erstellen Sie ein Sequenzielles Netzwerk analog zu dem ersten Versuch und erhöhen Sie die Anzahl der Schichten und auch Neuronen pro Schicht. <br>**Achtung** Hierdurch wird die Trainingszeit deutlich erhöht. Vergleichen Sie also vor dem Training die Anzahl an optimierbaren Parameter.<br><br>\n",
    "**Regularisierung** <br>\n",
    "Um große Netzwerke trainieren zu können, wurden viele Methoden entwickelt um ein Overfitting zu verhindern und das Netzwerk zu regularisieren.\n",
    "Bei dem Training von Neuronalen Netzen werden die Gewichte zu Beginn zufällig initialisiert. Durch das Gradient-Descent Verfahren, werden diese diese nun optimiert. Hierbei kann es dazu kommen, dass die Vorhersage des Netzes auf wenige Gewichte gestützt wird, die zu Beginn des Trainings zufällig in einem guten Bereich lagen. Bei den Trainingsschritten werden diese Gewichte also immer \"wichtiger\" und viele andere Gewichte und Neuronen \"deaktiviert\". Um dies zu verhindern, wurde unter anderem die Methode *DropOut* entwickelt, bei der in jedem Trainingsschritt eine zufällige Anzahl an Neuronen deaktiviert werden. So ist das Netzwerk gezwungen redundanzen zu entwickeln und so besser zu generalisieren. Es entstehen robustere Netze. Diese Methode ist einfach zu integrieren, indem hinter dem *Dense*-Layer eine Zeile mit dem Befehl: `keras.layers.Dropout(p)`angefügt wird, wobei *p* der Anteil(0-1) an Neuronen ist, die zufällig pro Schritt deaktiviert werden. Ein üblicher Wert liegt zwischen 5-10%.\n",
    "***Achtung***: Fügen Sie Dropout nicht hinter der Ausgabe Schicht ein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition des Modells\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        ### Anfang ###\n",
    "        keras.layers.Dense(..., activation='...',input_shape=(784,)),\n",
    "        ...\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "        ### Ende ###\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kompilierung V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das neue Netzwerk sollte ebenfalls die initiale *Learning Rate* angepasst werden. So beeinflusst diese auch das erreichbare Ergebnis. Die Berechnung eines Optimums ist jedoch relativ aufwendig. In dem folgenden Code wurde eine *Learning Rate* von $\\eta$ = 0.005 angegeben, die für unser größeres Netzwerk gut gepasst hat. Abhängig von der, von Ihnen definierten Architektur, kann dieser Wert jedoch variieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anfang ###\n",
    "opt = keras.optimizers.Adam(learning_rate=...)\n",
    "### Ende ###\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsprozess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun folgt der Trainingsprozess. Auch hierbei kann die Anzahl der Trainings-Epochen angepasst/optimiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anfang ###\n",
    "history = model.fit(X..., \n",
    "                    y..., \n",
    "                    epochs=...,\n",
    "                    batch_size=..., \n",
    "                    validation_split=0.2)\n",
    "### Ende ###\n",
    "\n",
    "# Speichern des Netzwerks\n",
    "path_to_model = 'keras_mnist_V2.h5'\n",
    "model.save(path_to_model)\n",
    "print('Das Modell wurde als: \"%s\" gespeichert\\n' % path_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analog zu dem ersten Netz, speichert der folgende Code das neue Netzwerk unter `'keras_mnist_V2.h5'`ab und gibt wieder den Verlauf der Präzision und des Verlustes über der Anzahl der Trainierten Epochen an. Am Schluss ist die Evaluation angefügt, um allem Metriken auf einen Blick zu haben. Führen Sie die Zelle aus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lade des Netzwerks\n",
    "path_to_model = 'keras_mnist_V2.h5'\n",
    "model = keras.models.load_model(path_to_model)\n",
    "print('Das Modell: \"%s\" wurde geladen\\n' % path_to_model)\n",
    "\n",
    "# Anzeige des Trainingsfortschritt - Präzision\n",
    "plt.plot(history.history['accuracy'])# je nach Keras Version auch 'acc'\n",
    "plt.plot(history.history['val_accuracy']) # je nach Keras Version auch 'val_acc'\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Accuracy Trainingssatz', 'Accuracy Testsatz'], loc='lower right')\n",
    "\n",
    "# Anzeige des Trainingsfortschritt - Loss\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Verlust Trainingssatz', 'Verlust Testsatz'], loc='upper right')\n",
    "\n",
    "# Evaluation\n",
    "loss_and_metrics = model.evaluate(X_evaluation, y_evaluation)\n",
    "\n",
    "print(\"Test Loss:     %.3f\"% loss_and_metrics[0])\n",
    "print(\"Test Accuracy: %.2f\"% (loss_and_metrics[1]*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoffentlich ist die Präzision über das erste Ergebnis gestiegen. Falls nicht, sollten Sie die vorherigen Werte ändern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation mit den selbstgeschriebenen Bildern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch mit diesem neu trainierten Netz können unsere eigenen Biler ausgewertet werden. <br>\n",
    "**Aufgabe:** Kopierte Sie dazu den Befehl von dem aus dem **Abschnitt 1.10** und passen Sie den Namen des gespeicherten Modells an das neue gespeicherte Netz `'keras_mnist_V2.h5'`an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anfang ###\n",
    "...\n",
    "### Ende ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation der Buchstaben von A-Z (Zusatz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basierend auf dem NIST-Datensatz wurde von [Kaggle](https://www.kaggle.com) ein Datensatz erstellt, der wie der MNIST Datensatz aus 28x28 Pixeln besteht. Der Workflow von Aufbereitung bis Training kann hier also übernommen werden. Wenn Sie mit dem Optimieren des MNIST Netzes bereits fertig sind, dann nutzen Sie wieder die Funktion: `az_data, az_label = lade_daten(az_path)`. Die Normierung der Daten und das Erstellen des Netzes können Sie analog zu der Vorherigen Aufgabe angehen.<br>\n",
    "**Erinnerung** Fügen Sie den MLE-Ordner bei Verwendung von **COLAB** hinzu: `'MLE-School/...` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anfang ###\n",
    "az_path = './06_Datasets/az_Data.npz' \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erkunden Sie den Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Gegensatz zu dem MNIST-Datensatz ist hier die Verteilung nicht sehr gleichmäßig. Eine Möglichkeit dies an zu passen, wäre die Data-Augmentation. Hierbei werden die Bilder beispielsweise leicht gedreht, verschoben oder skaliert und sind somit für den Algorithmus ein unbekannter Datenpunkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zahl, häufigkeit_im_Datensatz = np.unique(az_label.flatten(), return_counts=True)\n",
    "plt.bar(Zahl, häufigkeit_im_Datensatz)\n",
    "plt.xticks(Zahl, 'ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "plt.xlabel('Nummer in dem Bild')\n",
    "plt.ylabel('Anzahl in dem Datensatz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normieren der Daten und Training der Netze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analog zu den vorherigen Beispielen können Sie ein ANN auf diesen Datensatz trainieren. Für die Evaluation haben wir ebenfalls Bilder bereit gestellt:`'./02_Test-images/b1.jpg'`-`'./02_Test-images/b3.jpg'`.\n",
    "**Erinnerung** Fügen Sie den MLE-Ordner bei Verwendung von **COLAB** hinzu: `'MLE-School/...` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ende ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie gehts weiter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schreiben Sie selber eine Zahlenreihe auf das Papier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierbei ist die Skalierung der Bilder ausschlaggebend, da die Funktion `Klassifiziere Bilder` die Dimensionen der Bilder für die Entscheidung verwendet, ob das gefundene Muster zu klein ist, oder ob das ein Buchstabe sein kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verwenden Sie Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den letzten Jahren haben sich die Convolutional Neural Networks als besonders für die Bilderkennung als State of the Art hervor getan. Ohne ins Detail zu gehen, haben wir hier ien kleines CNN gebaut. Wie Sie sehen, ist die Methodik der Netzwerk Definition die selbe. Einzig sind jetzt andere Arten der Schichten verwendet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilder zu Quadratischem Layout\n",
    "X_train_Q = X_train.reshape(-1,28,28,1)\n",
    "X_eval_Q = X_evaluation.reshape(-1,28,28,1)\n",
    "\n",
    "# Definition des Convolutional neural Network\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28,1)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation='relu', kernel_initializer='he_uniform'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "# compile model\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Trianing\n",
    "model.fit(X_train_Q, y_train, epochs=10, batch_size=1024, verbose=1)\n",
    "\n",
    "\n",
    "# Speichern des Netzwerks\n",
    "path_to_model = 'keras_mnist_CNN.h5'\n",
    "model.save(path_to_model)\n",
    "print('Das Modell wurde als: \"%s\" gespeichert\\n' % path_to_model)\n",
    "\n",
    "# Anzeige des Trainingsfortschritt - Präzision\n",
    "plt.plot(history.history['accuracy'])# je nach Keras Version auch 'acc'\n",
    "plt.plot(history.history['val_accuracy']) # je nach Keras Version auch 'val_acc'\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Accuracy Trainingssatz', 'Accuracy Testsatz'], loc='lower right')\n",
    "\n",
    "# Anzeige des Trainingsfortschritt - Loss\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Verlust Trainingssatz', 'Verlust Testsatz'], loc='upper right')\n",
    "\n",
    "# Evaluation\n",
    "loss_and_metrics = model.evaluate(X_eval_Q, y_evaluation)\n",
    "\n",
    "print(\"Test Loss:     %.3f\"% loss_and_metrics[0])\n",
    "print(\"Test Accuracy: %.2f\"% (loss_and_metrics[1]*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = 'keras_mnist_CNN.h5'\n",
    "\n",
    "klassifiziere_bild('02_Test-images/n1.jpg', path_to_model, CNN=True)\n",
    "klassifiziere_bild('02_Test-images/n2.jpg', path_to_model, CNN=True)\n",
    "klassifiziere_bild('02_Test-images/n3.jpg', path_to_model, CNN=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN_az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilder zu Quadratischem Layout\n",
    "X_train_Q_az = X_train_az.reshape(-1,28,28,1)\n",
    "X_eval_Q_az = X_evaluation_az.reshape(-1,28,28,1)\n",
    "\n",
    "# Definition des Convolutional neural Network\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28,1)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation='relu', kernel_initializer='he_uniform'),\n",
    "    keras.layers.Dense(36, activation='softmax')\n",
    "    ])\n",
    "# compile model\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Training\n",
    "model.fit(X_train_Q, y_train, epochs=10, batch_size=1024, verbose=1)\n",
    "\n",
    "# Speichern des Netzwerks\n",
    "path_to_model = 'keras_az_CNN.h5'\n",
    "model.save(path_to_model)\n",
    "print('Das Modell wurde als: \"%s\" gespeichert\\n' % path_to_model)\n",
    "\n",
    "# Anzeige des Trainingsfortschritt - Präzision\n",
    "plt.plot(history.history['accuracy'])# je nach Keras Version auch 'acc'\n",
    "plt.plot(history.history['val_accuracy']) # je nach Keras Version auch 'val_acc'\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Accuracy Trainingssatz', 'Accuracy Testsatz'], loc='lower right')\n",
    "\n",
    "# Anzeige des Trainingsfortschritt - Loss\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Verlust Trainingssatz', 'Verlust Testsatz'], loc='upper right')\n",
    "\n",
    "# Evaluation\n",
    "loss_and_metrics = model.evaluate(X_eval_Q_az, y_evaluation_az)\n",
    "\n",
    "print(\"Test Loss:     %.3f\"% loss_and_metrics[0])\n",
    "print(\"Test Accuracy: %.2f\"% (loss_and_metrics[1]*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "klassifiziere_bild('02_Test-images/b1.jpg', 'keras_az_CNN.h5', CNN=True)\n",
    "klassifiziere_bild('02_Test-images/b2.jpg', 'keras_az_CNN.h5', CNN=True)\n",
    "klassifiziere_bild('02_Test-images/b3.jpg', 'keras_az_CNN.h5', CNN=True)\n",
    "klassifiziere_bild('02_Test-images/b4.jpg', 'keras_az_CNN.h5', CNN=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainable AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep_explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# select a set of background examples to take an expectation over\n",
    "background = X_train_Q[np.random.choice(X_train_Q.shape[0], 100, replace=False)]\n",
    "\n",
    "\n",
    "path_to_model = 'keras_mnist_CNN.h5'\n",
    "model = keras.models.load_model(path_to_model)\n",
    "\n",
    "# explain predictions of the model on three images\n",
    "e = shap.DeepExplainer(model, background)\n",
    "# ...or pass tensors directly\n",
    "# e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)\n",
    "shap_values = e.shap_values(X_eval_Q[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cover Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klassifiziere_bild('02_Test-images/MLE.jpg', 'keras_az_CNN.h5', True)\n",
    "klassifiziere_bild('02_Test-images/MLEz.jpg', 'keras_mnist_CNN.h5', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeitmessungen andere Algorithmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um den verwendeten Speicher zu evaluieren, wird ein weiteres Paket benötigt. Um dieses zu installieren, müssen Sie die Folgende Zeile zu einer Code Zeile ändern und einmal ausführen..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!conda install -c anaconda memory_profiler -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Module Laden und Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Test Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist_normiert, mnist_label.ravel(), test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "#training\n",
    "%time %memit model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "print('prediction')\n",
    "%time %memit y_pred = model.predict(X_test)\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NuSVC\n",
    "model = NuSVC()\n",
    "\n",
    "#training\n",
    "%time %memit model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "print('prediction')\n",
    "%time %memit y_pred = model.predict(X_test)\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "#training\n",
    "%time %memit model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "print('prediction')\n",
    "%time %memit y_pred = model.predict(X_test)\n",
    "# accuracy\n",
    "print(\"\\naccuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Tree\n",
    "model = ExtraTreeClassifier(random_state=0)\n",
    "\n",
    "#training\n",
    "%time %memit model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "print('prediction')\n",
    "%time %memit y_pred = model.predict(X_test)\n",
    "# accuracy\n",
    "print(\"\\naccuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forrest\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "#training\n",
    "%time %memit model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "print('prediction')\n",
    "%time %memit y_pred = model.predict(X_test)\n",
    "# accuracy\n",
    "print(\"\\naccuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### scikit learn MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "model = MLPClassifier(hidden_layer_sizes=(64,32,), max_iter=10, alpha=1e-4,\n",
    "                    solver='sgd', random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "#training\n",
    "start = time.time()\n",
    "%time %memit model.fit(X_train, y_train)\n",
    "print('actual time:', time.time()-start)\n",
    "# predict\n",
    "print('prediction')\n",
    "%time %memit y_pred = model.predict(X_test)\n",
    "# accuracy\n",
    "print(\"\\naccuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST_Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,9))\n",
    "im = np.zeros((1,28*20+1))\n",
    "for i in range(10):\n",
    "    itemindex = np.where(mnist_label.reshape(70000,)==i)[0]\n",
    "    row = np.zeros((28,1))\n",
    "    for k in range(20):\n",
    "        row = np.hstack((row, mnist_daten[itemindex[k]]))\n",
    "    im = np.vstack((im, row))\n",
    "plt.imshow(im, cmap='binary')\n",
    "fig.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "plt.savefig('Beispiel1.jpg', dpi=300, bbox_inches='tight', pad_inches=0.1, frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,9))\n",
    "im = np.zeros((28*11+1,1))\n",
    "for i in range(10):\n",
    "    itemindex = np.where(mnist_label.reshape(70000,)==i)[0]\n",
    "    row = np.zeros((1,28))\n",
    "    for k in range(11):\n",
    "        row = np.vstack((row, mnist_daten[itemindex[k]]))\n",
    "    im = np.hstack((im, row))\n",
    "plt.imshow(im, cmap='binary')\n",
    "fig.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "plt.savefig('Beispiel2.jpg', dpi=300, bbox_inches='tight', pad_inches=0.1, frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(mnist_daten[0], cmap='binary', interpolation='none')\n",
    "plt.title(\"Zahl: {}\".format(mnist_label[0][0]))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('Beispiel3.png', dpi=600, bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number in range(15):\n",
    "    new_im = []\n",
    "    n = 10\n",
    "    for row in mnist_daten[number]:\n",
    "        new_row= []\n",
    "        for pix in row:\n",
    "            new_row.append(255)\n",
    "            for i in range(n):\n",
    "                new_row.append(pix)\n",
    "        new_row.append(255)\n",
    "        for i in range(n):\n",
    "            new_im.append(new_row)\n",
    "        new_im.append(np.ones((len(new_row)))*255)\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(new_im, cmap='binary', interpolation='none')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.savefig('Nummer_%i.png'%number, dpi=600, bbox_inches='tight', pad_inches=0.1)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf29')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "08e3ed9748c573707b34472c59d1a8c58e1cdea5d49f0b477cad1c7731bc75cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
